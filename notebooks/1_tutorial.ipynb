{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 4th Big Data Analysis Contest 予測部門 チュートリアル\n",
    "\n",
    "## 概要\n",
    "「The 4th Big Data Analysis Contest」（ https://signate.jp/competitions/136 ）の実装例です。\n",
    "本チュートリアルでは、モデルの構築ではなく、データの理解のための探索的分析、可視化を中心とした内容としています。\n",
    "実装にはpython（versionは3.6.3）を使用。構成は以下のとおりです。\n",
    "\n",
    "- 必要なライブラリ\n",
    "- 必要なデータの用意\n",
    "- 実装\n",
    "    1. データの読み込み\n",
    "    2. データの理解\n",
    "    3. 投稿ファイルの作成\n",
    "- まとめ\n",
    "\n",
    "## 必要なライブラリ\n",
    "日付の処理にdatetime、ファイルの処理にpandas、基本的な数値計算にnumpy、可視化にmatplotlib, seabornを使用します。\n",
    "\n",
    "## 必要なデータの用意\n",
    "https://signate.jp/competitions/136 へアクセスし, 「データ」タブを押し, 以下のファイルをダウンロードします。\n",
    "データは、dataset フォルダへ纏めておきます。\n",
    "\n",
    "軌道検測_首都圏路線A (track_A.csv)\n",
    "軌道検測_首都圏路線B (track_B.csv)\n",
    "軌道検測_地方幹線C (track_C.csv)\n",
    "軌道検測_地方路線D (track_D.csv)\n",
    "設備台帳_首都圏路線A (equipment_A.csv)\n",
    "設備台帳_首都圏路線B (equipment_B.csv)\n",
    "設備台帳_地方幹線C (equipment_C.csv)\n",
    "設備台帳_地方路線D (equipment_D.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装\n",
    "まず必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込み\n",
    "4種類の軌道検測データを、路線名A,B,C,Dをキーとしたディクショナリに、項目\"date\"をタイムスタンプ型とした上で、データフレームとして読み込みます。\n",
    "設備台帳データも同様に読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "tracks={}\n",
    "for no in ['A','B']:\n",
    "# for no in ['A','B','C','D']:\n",
    "    tracks[no] = pd.read_csv(\"../data/raw/track_\" + no + \".csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipments={}\n",
    "# for no in ['A','B','C','D']:\n",
    "for no in ['A','B']:\n",
    "    equipments[no] = pd.read_csv(\"../data/raw/equipment_\" + no + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[\"A\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipments[\"A\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
